{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04709981",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364e546",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c57c87",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4453916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa564017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "datapath = 'data'\n",
    "dataset = load_files(datapath, load_content=False, shuffle=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image files as grayscale\n",
    "X = []\n",
    "for file in dataset['filenames']:\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img.flatten()\n",
    "    X.append(img)\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a616650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "X = pca.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten feature vectors and split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model with default slack C=1\n",
    "svm_mdl = svm.SVC(C=5)\n",
    "svm_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = svm_mdl.predict(X_test)\n",
    "print(f'Precision: {precision_score(preds, y_test)}\\nRecall: {recall_score(preds, y_test)}\\nF1: {f1_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-fold cross validation to determine best slack parameter (5)\n",
    "# WARNING - EXTREMELY LONG RUNTIME #\n",
    "#svm_tune = svm.SVC()\n",
    "#param_dict = {'C': [0.25, 0.5, 1, 2, 5]}\n",
    "#clf = GridSearchCV(svm_tune, param_dict, scoring='f1')\n",
    "#clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b6ed1",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8419e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e8a6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.6397, Train Acc: 0.6548\n",
      "Epoch [2/10], Train Loss: 0.5107, Train Acc: 0.7681\n",
      "Epoch [3/10], Train Loss: 0.3144, Train Acc: 0.8680\n",
      "Epoch [4/10], Train Loss: 0.2114, Train Acc: 0.9195\n",
      "Epoch [5/10], Train Loss: 0.0973, Train Acc: 0.9642\n",
      "Epoch [6/10], Train Loss: 0.0476, Train Acc: 0.9811\n",
      "Epoch [7/10], Train Loss: 0.0244, Train Acc: 0.9927\n",
      "Epoch [8/10], Train Loss: 0.0295, Train Acc: 0.9894\n",
      "Epoch [9/10], Train Loss: 0.0072, Train Acc: 0.9977\n",
      "Epoch [10/10], Train Loss: 0.0010, Train Acc: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Set device for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define transformation for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "data = datasets.ImageFolder('data/', transform=transform)\n",
    "\n",
    "# Define the ResNet18 model architecture\n",
    "model = resnet18()\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(data.classes))\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_f1 = 0.0\n",
    "    train_count = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Compute loss and f1\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        train_f1 += f1_score(predicted.cpu(), labels.cpu(), average='weighted') * images.size(0)\n",
    "        train_count += images.size(0)\n",
    "        \n",
    "    # calculate average training loss and f1 score\n",
    "    train_loss /= train_count\n",
    "    train_f1 /= train_count\n",
    "\n",
    "    # Print training loss and accuracy\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train F1: {:.4f}'.format(epoch+1, num_epochs, train_loss, train_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af51575",
   "metadata": {},
   "source": [
    "# Experiment NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0578f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
